#!/usr/bin/env python
import defopt
from pathlib import Path
import json
import os
import shutil
import subprocess
import itertools 



def distribute_samples(n_samples, n_workers):
    n_local = n_samples // n_workers
    res = [n_local for i in range(n_workers)]
    n_remainder = n_samples % n_workers
    for i in range(n_remainder):
        res[i] += 1
    return res


def remove_executables_in_dir(directory):
    executable = stat.S_IEXEC | stat.S_IXGRP | stat.S_IXOTH
    for filename in os.listdir(directory):
        if os.path.isfile(filename):
            st = os.stat(filename)
            mode = st.st_mode
            if mode & executable:
                os.remove(filename)    


def clean(*, config: Path):
    """
    Clean the experiment
    :param config: JSON configuration file
    """
    # read the config file
    with config.open('r') as f:
        meta = json.load(f)

    shutil.rmtree(Path(meta['run_dir']))



def prep(*, config: Path):
    """
    Prepare
    :param config: JSON configuration file
    """
    # read the config file
    with config.open('r') as f:
        meta = json.load(f)

    # runs some checks
    if not "project_dir" in meta:
        raise RuntimeError("need to have a project directory")
    if not os.path.isdir(meta["project_dir"]):
        raise RuntimeError(f"file {meta['project_dir']} is not a directory")
    if not "run_dir" in meta:
        raise RuntimeError("need to have a run directory")

    n_workers = meta['sim']['n_workers']
    n_samples = meta['sim']['n_samples']

    var_name, var_file = meta['sim']['output']['var'].split('.')
    units = meta['sim']['output']['units']

    n_local_samples = distribute_samples(n_samples, n_workers)
    indx_end_local = [e for e in itertools.accumulate(n_local_samples)]
    indx_beg_local = [indx_end_local[i] - n_local_samples[i] for i in range(len(n_local_samples))]

    for worker_id in range(n_workers):

        worker_id_str = str(worker_id).zfill(4)
        worker_run_path = Path(meta['run_dir']) / Path(f'worker_{worker_id_str}')

        # copy the SWAT files to the worker run directory
        print(f"...copying data from {meta['project_dir']} to {worker_run_path}")
        shutil.copytree(meta['project_dir'], worker_run_path)

        # copy the param input file
        input_rds = worker_run_path / Path('input.rds')
        shutil.copyfile(meta['sim']['input'], input_rds) 

        # build the script
        r_script = f"""
library(SWATplusR)
library(dplyr)

# start row
ibeg <- {indx_beg_local[worker_id] + 1}
# end row
iend <- {indx_end_local[worker_id]}

# get the params for this worker
param <- readRDS('input.rds')[ibeg:iend,]

# run the parameter scan
res <- run_swat2012(project_path = \'./\',
                    output = list(q=define_output(file = \'{var_file}\',
                              variable = \'{var_name}\', unit={units})),
                    parameter = param,
                    n_thread = {meta['sim']['n_threads_per_worker']})

# save the results
saveRDS(res, file = \'./result.rds\')
"""
        with open(worker_run_path / Path(f'run.R'), 'w') as f:
            f.write(r_script)


def run(*, config: Path):
    """
    Run
    :param config: configuration file
    """
    # read the config file
    with config.open('r') as f:
        meta = json.load(f)


    # remove any executable file
    print(f"removing execs")
    remove_executables_in_dir(meta['run_dir'])
    print(f"done")

    # copy the executable over to the run directory
    print(f"copying swat exec")
    shutil.copy(meta['swat_exec'], Path(meta['run_dir']) / Path('swat'))
    print(f"done")

    # create slurm job
    nworkers = meta['sim']['n_workers']
    nthreads = meta['sim']['n_threads_per_worker']
    act = meta['scheduler']['slurm']['account']
    tim = meta['scheduler']['slurm']['time']
    mem = meta['scheduler']['slurm']['mem']
    slurm_script = f"""#!/bin/bash -e
#SBATCH --job-name=swt-{nworkers}w-{nthreads}t
#SBATCH --account={act}       
#SBATCH --time={tim}
#SBATCH --mem={mem}
#SBATCH --array=0-{nworkers - 1}
#SBATCH --ntasks=1
#SBATCH --cpus-per-task={nthreads}
#SBATCH --hint=nomultithread

# on mahuika, need these modules
ml Python R intel

# prepending the worker_id with zeros
worker_id=$(python -c "import sys; n = sys.argv[1]; print(n.zfill(4))" ${{SLURM_ARRAY_TASK_ID}})

cd worker_${{worker_id}}
Rscript run.R
"""
    fname = meta['run_dir'] / Path(f'run.sl')
    with open(fname, 'w') as f:
            f.write(slurm_script)

    print(f"You will need to submit SLURM script {fname}")


def analyse(*, config: Path):
    """
    Analyse the results
    :param config: configuration file
    """
    pass


if __name__ == '__main__':
    defopt.run([clean, prep, run, analyse])
